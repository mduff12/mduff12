{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_401k = pd.read_csv('./401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_401k.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_401k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Occupation, education level*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The model may predict advertising to one race over another, possibly creating a barrier to access, or creating a bias within the team/company on who to target for financial services. We would not want to avoid targeting a certain group of people due to their race.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We would want to make sure that some of the variables are not collinear. For example, marriage and family size may be too highly correlated to include both in the model. We would want to test them for collinearity before including them. Similary, Age^2 seems to be an engineered feature that would be directly correlated to Age, so we would not want to include age, just Age^2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/52585/what-happens-when-i-include-a-squared-variable-in-my-regression\n",
    "\n",
    "*agesq, incsq are squared versions of the variables. This may be because income eventually will reach a plateau.*\n",
    "\n",
    "*Squaring the data will also standardaize variables like age, since they are so far away from income it would be helpful to make them closer together to understand their relationship.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*both age^2 and inc^2 are in the data dictionary twice. When examining the data, it seems that the variables are correct though.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**Multiple Linear regression** - multiple variables to predict y and interpretable cofficients make this model very useful in this situation. Since we are predicting a numeric variable, we can use MLR.\n",
    "\n",
    "**Logistic regression** - this predicts categories, so it would not be helpful in this problem. \n",
    "\n",
    "**KNearest Neighbors** - non-parametric (not making assumptions about the distribution of the data), uses distance so the data needs to be scaled, is difficult to interpret the features which is importnat to our model because we want to understand the features. \n",
    "\n",
    "**Decision Tree Regression** - We don't have to scale the data, it is prone to overfitting, and is easy to interpret the features, which is what we are looking for in this question. \n",
    "\n",
    "**Random Forests and ExtraTrees** - This de-correlates the decision tree regression and helps take away variance by employing random subset sampling in the algorithm. If the Decision tree regression is too overfit, it is useful to employe these to help reduce variance and strenghten the model. \n",
    "\n",
    "**Adaboost Model** - An ensemble method of modeling that assigns weights to specific features with the goal of correct misclassifications\n",
    "\n",
    "**Suppor Vector Regressor** - Black box model, which is not helpful for interpretation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df_401k[['marr','male','age','fsize','nettfa','incsq','agesq']]\n",
    "y= df_401k['inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8948254673897011, Testing Score: 0.9055024120733456\n"
     ]
    }
   ],
   "source": [
    "#instantiate the Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "#fit the model \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#score the  data\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}, Testing Score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = lr.predict(X_train)\n",
    "\n",
    "resids = preds - y_train\n",
    "\n",
    "rmse_train_mlr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test rmse\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "resids = preds - y_test\n",
    "\n",
    "rmse_mlr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnr = KNeighborsRegressor(n_neighbors=5)\n",
    "knnr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9795704183969427,Testing Score: 0.9728418554699854\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {knnr.score(Z_train, y_train)},Testing Score: {knnr.score(Z_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = knnr.predict(Z_train)\n",
    "\n",
    "rmse_train_knnr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rmse\n",
    "\n",
    "preds = knnr.predict(Z_test)\n",
    "\n",
    "rmse_knnr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9999481486457086)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(Z_train, y_train), dtr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = dtr.predict(Z_train)\n",
    "\n",
    "rmse_train_dtr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rmse\n",
    "\n",
    "preds = dtr.predict(Z_test)\n",
    "\n",
    "rmse_dtr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr = BaggingRegressor(random_state = 42, base_estimator = DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(), random_state=42)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.999989416529091, 0.9999883790392515)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgr.score(Z_train, y_train), bgr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = bgr.predict(Z_train)\n",
    "\n",
    "rmse_train_bgr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rmse\n",
    "preds = bgr.predict(Z_test)\n",
    "\n",
    "rmse_bgr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999889348368476, 0.9999907283001671)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(Z_train, y_train),rfr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = rfr.predict(Z_train)\n",
    "\n",
    "rmse_train_rfr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rmse\n",
    "\n",
    "preds = rfr.predict(Z_test)\n",
    "\n",
    "rmse_rfr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(random_state=42)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913321095472987"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916962982297579"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(max_depth=3, random_state=1608637542),\n",
       " DecisionTreeRegressor(max_depth=3, random_state=1776589882),\n",
       " DecisionTreeRegressor(max_depth=3, random_state=1666910835),\n",
       " DecisionTreeRegressor(max_depth=3, random_state=754668208),\n",
       " DecisionTreeRegressor(max_depth=3, random_state=1177281088)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.estimators_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = abr.predict(Z_train)\n",
    "\n",
    "rmse_train_abr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rmse\n",
    "\n",
    "preds = abr.predict(Z_test)\n",
    "\n",
    "rmse_abr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = LinearSVR(random_state=42, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(max_iter=5000, random_state=42)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8149823407006432, 0.8266033728325769)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(Z_train, y_train), svr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train rmse\n",
    "preds = svr.predict(Z_train)\n",
    "\n",
    "rmse_train_svr = np.sqrt(metrics.mean_squared_error(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test rmse\n",
    "preds = svr.predict(Z_test)\n",
    "\n",
    "rmse_svr = np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bootstrapping is a resampling method by which the model chooses random samples of the population then replaces them each time. The model is fit on each new bootstrapped sample. All of those models are then combined.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "*A decision tree is a model that finds rules based on the X dataset and then splits the data into smaller subset, each time making a decision on how to split the data. 'Bagging' stands for bootstrap aggregating. The model pulls samples from the population and then puts it back. Each time it pulls, it runs the model. It then puts back the sample into the population. Then, it creates another decision tree, and runs the model. Finally, the models are then aggregated to make a final decision.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bagged decision trees refers to resampling the data for each decision tree and then returning it to the overall sample before aggregating the restuls of each decision and returning a decision. A random forest refers to a method of de-correlating the decisions. At each split/decision, the algorithm selects a **random** subset of the data in its decisions. This prevents the correlation that tends to occur because some features may be really strong indicators of the target, and therefore the algorithm will keep using them in each decision tree.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If the decision tree is overfit, a random forest will help reduce the variance because it picks a random subset of the data for each tree.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: 7.506111330932499\n",
      "KNN: 4.02396956785657\n",
      "DTR: 0.14957548524733985\n",
      "BGR: 0.08323877058190046\n",
      "RFR: 0.0806068262554918\n",
      "ABR: 2.2250537752157458\n",
      "SVR: 10.167752419073258\n"
     ]
    }
   ],
   "source": [
    "print(f'MLR: {rmse_mlr}'),\n",
    "print(f'KNN: {rmse_knnr}'),\n",
    "print(f'DTR: {rmse_dtr}'),\n",
    "print(f'BGR: {rmse_bgr}'),\n",
    "print(f'RFR: {rmse_rfr}'),\n",
    "print(f'ABR: {rmse_abr}'),\n",
    "print(f'SVR: {rmse_svr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: 7.776216516193241\n",
      "KNN: 3.4272263258974696\n",
      "DTR: 5.553987297632147e-16\n",
      "BGR: 0.07800583843213096\n",
      "RFR: 0.07976125153602444\n",
      "ABR: 2.2323883936942956\n",
      "SVR: 10.313822194654584\n"
     ]
    }
   ],
   "source": [
    "print(f'MLR: {rmse_train_mlr}'),\n",
    "print(f'KNN: {rmse_train_knnr}'),\n",
    "print(f'DTR: {rmse_train_dtr}'),\n",
    "print(f'BGR: {rmse_train_bgr}'),\n",
    "print(f'RFR: {rmse_train_rfr}'),\n",
    "print(f'ABR: {rmse_train_abr}'),\n",
    "print(f'SVR: {rmse_train_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'rmse': [rmse_mlr,rmse_knnr,rmse_dtr,rmse_bgr,rmse_rfr,rmse_abr, rmse_svr], 'train_rmse': [rmse_train_mlr,rmse_train_knnr,rmse_train_dtr,rmse_train_bgr,rmse_train_rfr,rmse_train_abr,rmse_train_svr]}\n",
    "index = ['MLR',\n",
    "'KNN',\n",
    "'DTR',\n",
    "'BGR',\n",
    "'RFR',\n",
    "'ABR',\n",
    "'SVR']\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.index = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>7.506111</td>\n",
       "      <td>7.776217e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>4.023970</td>\n",
       "      <td>3.427226e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTR</th>\n",
       "      <td>0.175827</td>\n",
       "      <td>5.553987e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGR</th>\n",
       "      <td>0.083239</td>\n",
       "      <td>7.800584e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFR</th>\n",
       "      <td>0.074351</td>\n",
       "      <td>7.976125e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse    train_rmse\n",
       "MLR  7.506111  7.776217e+00\n",
       "KNN  4.023970  3.427226e+00\n",
       "DTR  0.175827  5.553987e-16\n",
       "BGR  0.083239  7.800584e-02\n",
       "RFR  0.074351  7.976125e-02"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.417756069233555"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline RMSE:\n",
    "baseline = metrics.mean_squared_error(y_test, [y_train.mean()]*len(y_test), squared=False)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*it looks likes the Decision Tree, Bagged Decision Tree and Random Forest are overfit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "*I would pick the MLR because the training and testing scores are very close together*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I would continue feature engineering via polynomial features and add gridsearch to find the best hyper parameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you are participating in a 401k, you are already eligible for the 401k, so these variables would be correlated.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** - this predicts categories, so it would be helpful in this problem.\n",
    "\n",
    "**KNearest Neighbors** - non-parametric (not making assumptions about the distribution of the data), uses distance so the data needs to be scaled, is difficult to interpret the features but we are just trying to predict whether the person is eligible.\n",
    "\n",
    "**Decision Tree classifier** - We don't have to scale the data, it is prone to overfitting. \n",
    "\n",
    "**Random Forests and ExtraTrees Classfiier** - This de-correlates the decision tree regression and helps take away variance by employing random subset sampling in the algorithm. If the Decision tree regression is too overfit, it is useful to employ these to help reduce variance and strenghten the model.\n",
    "\n",
    "**Adaboost Classifier** - An ensemble method of modeling that assigns weights to specific features with the goal of correct misclassifications.\n",
    "\n",
    "**Suppor Vector Classifier** - Black box model predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_401k.drop(columns =['e401k','p401k'])\n",
    "y = df_401k['e401k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.607871\n",
       "1    0.392129\n",
       "Name: e401k, dtype: float64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy of our baseline model?\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6569867740080506, 0.6550237171194481)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(Z_train, y_train)\n",
    "lgr.score(Z_train, y_train), lgr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7515813686026452, 0.6399310047434239)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Z_train, y_train)\n",
    "knn.score(Z_train, y_train), knn.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5890470030185425)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(Z_train, y_train)\n",
    "dtc.score(Z_train, y_train), dtc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagged decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9764232317423807, 0.6338939197930142)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgc = BaggingClassifier()\n",
    "bgc.fit(Z_train, y_train)\n",
    "bgc.score(Z_train, y_train), bgc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998562392179413, 0.6580422595946529)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(Z_train, y_train)\n",
    "rfc.score(Z_train, y_train), rfc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6520051746442432)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=500)\n",
    "etc.fit(Z_train, y_train)\n",
    "etc.score(Z_train, y_train), etc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6927832087406556, 0.685640362225097)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(Z_train, y_train)\n",
    "abc.score(Z_train, y_train), abc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.683870040253019, 0.6774471755066839)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(Z_train, y_train)\n",
    "svc.score(Z_train, y_train), svc.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Positive class = eligible for 401k**\n",
    "\n",
    "*False Positive* = not eligible for 401k but classified **as** eligible \n",
    "\n",
    "*False Negative* = eligible for 401k but classified as **not** eligible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I would argue we should minimize false negatives, because it could prevent people from saving their money and taking advantage of the 401k investments.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/277347/optimise-svm-to-avoid-false-negative-in-binary-classification\n",
    "\n",
    "\n",
    "*I would utilize the SVM in my final model, because the training and testing score are closes together. Therefor I would tune the hyper-parameter 'class weight'.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "*Precision = true positives/all results that were classified as positive*\n",
    "\n",
    "*Recall = true positives/false negatives*\n",
    "\n",
    "*The f-score is the mean of precision and recall, which would be the true positives over all positives + false negatives.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with help from lab review breakfast hour\n",
    "\n",
    "def f1_scorer(model,X_train, X_test, y_train, y_test):\n",
    "    f1_train = f1_score(y_true=y_train,\n",
    "                       y_pred = model.predict(X_train))\n",
    "    f1_test = f1_score(y_true = y_test,\n",
    "                      y_pred = model.predict(X_test))\n",
    "    print(f'Training score: {model} is {f1_train}, Testing score: {model} is {f1_test}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: LogisticRegression() is 0.0, Testing score: LogisticRegression() is 0.0\n",
      "\n",
      "Training score: KNeighborsClassifier() is 0.07669808254793631, Testing score: KNeighborsClassifier() is 0.08040201005025127\n",
      "\n",
      "Training score: DecisionTreeClassifier() is 0.5576208178438662, Testing score: DecisionTreeClassifier() is 0.5456638526477361\n",
      "\n",
      "Training score: BaggingClassifier() is 0.5799736495388669, Testing score: BaggingClassifier() is 0.5800391389432484\n",
      "\n",
      "Training score: RandomForestClassifier() is 0.15424912689173456, Testing score: RandomForestClassifier() is 0.15602836879432622\n",
      "\n",
      "Training score: ExtraTreesClassifier(n_estimators=500) is 0.246064139941691, Testing score: ExtraTreesClassifier(n_estimators=500) is 0.264783759929391\n",
      "\n",
      "Training score: AdaBoostClassifier() is 0.48099516240497575, Testing score: AdaBoostClassifier() is 0.4846912298910223\n",
      "\n",
      "Training score: SVC() is 0.0, Testing score: SVC() is 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scorer(lgr,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(knn,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(dtc,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(bgc,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(rfc,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(etc,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(abc,X_train, X_test, y_train, y_test)\n",
    "\n",
    "f1_scorer(svc,X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either the precision or the recall is zero.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I do not see evidence of overfitting in these scores, they are either lowest possible or very simliar between testing and training.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "*I would use the Adaboost Classifier as it has the highest f1 scores in both training and testing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I would utilize gridsearch to tune the hyper parameters like the decision tree nodes and estimators.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REgre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
