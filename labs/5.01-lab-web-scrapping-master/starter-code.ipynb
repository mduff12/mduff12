{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a soup object from the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/'\n",
    "res=requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the home page soup for every restaurant\n",
    "\n",
    "Note: Your best bet is to create a list of dictionaries, one for each restaurant. Each dictionary contains the restaurant's name and path from the `href`. The result of your scrape should look something like this:\n",
    "\n",
    "```python\n",
    "restaurants = [\n",
    "    {'name': 'A&W Restaurants', 'href': 'restaurants/1.html'}, \n",
    "    {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"navbar-brand\" href=\"/\">Nutrition Information</a>,\n",
       " <a href=\"restaurants/1.html\">A&amp;W Restaurants</a>,\n",
       " <a href=\"restaurants/2.html\">Applebee's</a>,\n",
       " <a href=\"restaurants/3.html\">Arby's</a>,\n",
       " <a href=\"restaurants/4.html\">Atlanta Bread Company</a>,\n",
       " <a href=\"restaurants/5.html\">Bojangle's Famous Chicken 'n Biscuits</a>,\n",
       " <a href=\"restaurants/6.html\">Buffalo Wild Wings</a>,\n",
       " <a href=\"restaurants/7.html\">Burger King</a>,\n",
       " <a href=\"restaurants/8.html\">Captain D's</a>,\n",
       " <a href=\"restaurants/9.html\">Carl's Jr.</a>,\n",
       " <a href=\"restaurants/10.html\">Charley's Grilled Subs</a>,\n",
       " <a href=\"restaurants/11.html\">Chick-fil-A</a>,\n",
       " <a href=\"restaurants/12.html\">Chili's</a>,\n",
       " <a href=\"restaurants/13.html\">Chipotle Mexican Grill</a>,\n",
       " <a href=\"restaurants/14.html\">Church's</a>,\n",
       " <a href=\"restaurants/15.html\">Corner Bakery Cafe</a>,\n",
       " <a href=\"restaurants/16.html\">Dairy Queen</a>,\n",
       " <a href=\"restaurants/17.html\">Denny's</a>,\n",
       " <a href=\"restaurants/18.html\">El Pollo Loco</a>,\n",
       " <a href=\"restaurants/19.html\">FATZ</a>,\n",
       " <a href=\"restaurants/20.html\">Fazoli's</a>,\n",
       " <a href=\"restaurants/21.html\">Five Guys Burgers and Fries</a>,\n",
       " <a href=\"restaurants/22.html\">Golden Chick</a>,\n",
       " <a href=\"restaurants/23.html\">Hardee's</a>,\n",
       " <a href=\"restaurants/24.html\">IHOP</a>,\n",
       " <a href=\"restaurants/25.html\">In-N-Out Burger</a>,\n",
       " <a href=\"restaurants/26.html\">Jack in the Box</a>,\n",
       " <a href=\"restaurants/27.html\">Jimmy Johns</a>,\n",
       " <a href=\"restaurants/28.html\">Joe's Crab Shack</a>,\n",
       " <a href=\"restaurants/29.html\">KFC</a>,\n",
       " <a href=\"restaurants/30.html\">McDonald's</a>,\n",
       " <a href=\"restaurants/31.html\">O'Charley's</a>,\n",
       " <a href=\"restaurants/32.html\">Olive Garden</a>,\n",
       " <a href=\"restaurants/33.html\">Outback Steakhouse</a>,\n",
       " <a href=\"restaurants/34.html\">Panda Express</a>,\n",
       " <a href=\"restaurants/35.html\">Panera Bread</a>,\n",
       " <a href=\"restaurants/36.html\">Popeye's</a>,\n",
       " <a href=\"restaurants/37.html\">Quiznos</a>,\n",
       " <a href=\"restaurants/38.html\">Red Robin Gourmet Burgers</a>,\n",
       " <a href=\"restaurants/39.html\">Romano's Macaroni Grill</a>,\n",
       " <a href=\"restaurants/40.html\">Ruby Tuesday</a>,\n",
       " <a href=\"restaurants/41.html\">Subway</a>,\n",
       " <a href=\"restaurants/42.html\">Taco Bell</a>,\n",
       " <a href=\"restaurants/43.html\">Taco Bueno</a>,\n",
       " <a href=\"restaurants/44.html\">Wendy's</a>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nutrition Information',\n",
       " 'A&W Restaurants',\n",
       " \"Applebee's\",\n",
       " \"Arby's\",\n",
       " 'Atlanta Bread Company',\n",
       " \"Bojangle's Famous Chicken 'n Biscuits\",\n",
       " 'Buffalo Wild Wings',\n",
       " 'Burger King',\n",
       " \"Captain D's\",\n",
       " \"Carl's Jr.\",\n",
       " \"Charley's Grilled Subs\",\n",
       " 'Chick-fil-A',\n",
       " \"Chili's\",\n",
       " 'Chipotle Mexican Grill',\n",
       " \"Church's\",\n",
       " 'Corner Bakery Cafe',\n",
       " 'Dairy Queen',\n",
       " \"Denny's\",\n",
       " 'El Pollo Loco',\n",
       " 'FATZ',\n",
       " \"Fazoli's\",\n",
       " 'Five Guys Burgers and Fries',\n",
       " 'Golden Chick',\n",
       " \"Hardee's\",\n",
       " 'IHOP',\n",
       " 'In-N-Out Burger',\n",
       " 'Jack in the Box',\n",
       " 'Jimmy Johns',\n",
       " \"Joe's Crab Shack\",\n",
       " 'KFC',\n",
       " \"McDonald's\",\n",
       " \"O'Charley's\",\n",
       " 'Olive Garden',\n",
       " 'Outback Steakhouse',\n",
       " 'Panda Express',\n",
       " 'Panera Bread',\n",
       " \"Popeye's\",\n",
       " 'Quiznos',\n",
       " 'Red Robin Gourmet Burgers',\n",
       " \"Romano's Macaroni Grill\",\n",
       " 'Ruby Tuesday',\n",
       " 'Subway',\n",
       " 'Taco Bell',\n",
       " 'Taco Bueno',\n",
       " \"Wendy's\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find all names of the restaraunts\n",
    "[a.text for a in soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': ['navbar-brand'], 'href': '/'},\n",
       " {'href': 'restaurants/1.html'},\n",
       " {'href': 'restaurants/2.html'},\n",
       " {'href': 'restaurants/3.html'},\n",
       " {'href': 'restaurants/4.html'},\n",
       " {'href': 'restaurants/5.html'},\n",
       " {'href': 'restaurants/6.html'},\n",
       " {'href': 'restaurants/7.html'},\n",
       " {'href': 'restaurants/8.html'},\n",
       " {'href': 'restaurants/9.html'},\n",
       " {'href': 'restaurants/10.html'},\n",
       " {'href': 'restaurants/11.html'},\n",
       " {'href': 'restaurants/12.html'},\n",
       " {'href': 'restaurants/13.html'},\n",
       " {'href': 'restaurants/14.html'},\n",
       " {'href': 'restaurants/15.html'},\n",
       " {'href': 'restaurants/16.html'},\n",
       " {'href': 'restaurants/17.html'},\n",
       " {'href': 'restaurants/18.html'},\n",
       " {'href': 'restaurants/19.html'},\n",
       " {'href': 'restaurants/20.html'},\n",
       " {'href': 'restaurants/21.html'},\n",
       " {'href': 'restaurants/22.html'},\n",
       " {'href': 'restaurants/23.html'},\n",
       " {'href': 'restaurants/24.html'},\n",
       " {'href': 'restaurants/25.html'},\n",
       " {'href': 'restaurants/26.html'},\n",
       " {'href': 'restaurants/27.html'},\n",
       " {'href': 'restaurants/28.html'},\n",
       " {'href': 'restaurants/29.html'},\n",
       " {'href': 'restaurants/30.html'},\n",
       " {'href': 'restaurants/31.html'},\n",
       " {'href': 'restaurants/32.html'},\n",
       " {'href': 'restaurants/33.html'},\n",
       " {'href': 'restaurants/34.html'},\n",
       " {'href': 'restaurants/35.html'},\n",
       " {'href': 'restaurants/36.html'},\n",
       " {'href': 'restaurants/37.html'},\n",
       " {'href': 'restaurants/38.html'},\n",
       " {'href': 'restaurants/39.html'},\n",
       " {'href': 'restaurants/40.html'},\n",
       " {'href': 'restaurants/41.html'},\n",
       " {'href': 'restaurants/42.html'},\n",
       " {'href': 'restaurants/43.html'},\n",
       " {'href': 'restaurants/44.html'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all hrefs\n",
    "[tag.attrs for tag in soup.find_all('a')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [name.text for name in soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = [link.attrs['href'] for link in soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-convert-two-lists-into-a-dictionary/\n",
    "# restaurants = dict(zip(name, href))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Nutrition Information', 'href': '/'}, {'name': 'A&W Restaurants', 'href': 'restaurants/1.html'}, {'name': \"Applebee's\", 'href': 'restaurants/2.html'}, {'name': \"Arby's\", 'href': 'restaurants/3.html'}, {'name': 'Atlanta Bread Company', 'href': 'restaurants/4.html'}, {'name': \"Bojangle's Famous Chicken 'n Biscuits\", 'href': 'restaurants/5.html'}, {'name': 'Buffalo Wild Wings', 'href': 'restaurants/6.html'}, {'name': 'Burger King', 'href': 'restaurants/7.html'}, {'name': \"Captain D's\", 'href': 'restaurants/8.html'}, {'name': \"Carl's Jr.\", 'href': 'restaurants/9.html'}, {'name': \"Charley's Grilled Subs\", 'href': 'restaurants/10.html'}, {'name': 'Chick-fil-A', 'href': 'restaurants/11.html'}, {'name': \"Chili's\", 'href': 'restaurants/12.html'}, {'name': 'Chipotle Mexican Grill', 'href': 'restaurants/13.html'}, {'name': \"Church's\", 'href': 'restaurants/14.html'}, {'name': 'Corner Bakery Cafe', 'href': 'restaurants/15.html'}, {'name': 'Dairy Queen', 'href': 'restaurants/16.html'}, {'name': \"Denny's\", 'href': 'restaurants/17.html'}, {'name': 'El Pollo Loco', 'href': 'restaurants/18.html'}, {'name': 'FATZ', 'href': 'restaurants/19.html'}, {'name': \"Fazoli's\", 'href': 'restaurants/20.html'}, {'name': 'Five Guys Burgers and Fries', 'href': 'restaurants/21.html'}, {'name': 'Golden Chick', 'href': 'restaurants/22.html'}, {'name': \"Hardee's\", 'href': 'restaurants/23.html'}, {'name': 'IHOP', 'href': 'restaurants/24.html'}, {'name': 'In-N-Out Burger', 'href': 'restaurants/25.html'}, {'name': 'Jack in the Box', 'href': 'restaurants/26.html'}, {'name': 'Jimmy Johns', 'href': 'restaurants/27.html'}, {'name': \"Joe's Crab Shack\", 'href': 'restaurants/28.html'}, {'name': 'KFC', 'href': 'restaurants/29.html'}, {'name': \"McDonald's\", 'href': 'restaurants/30.html'}, {'name': \"O'Charley's\", 'href': 'restaurants/31.html'}, {'name': 'Olive Garden', 'href': 'restaurants/32.html'}, {'name': 'Outback Steakhouse', 'href': 'restaurants/33.html'}, {'name': 'Panda Express', 'href': 'restaurants/34.html'}, {'name': 'Panera Bread', 'href': 'restaurants/35.html'}, {'name': \"Popeye's\", 'href': 'restaurants/36.html'}, {'name': 'Quiznos', 'href': 'restaurants/37.html'}, {'name': 'Red Robin Gourmet Burgers', 'href': 'restaurants/38.html'}, {'name': \"Romano's Macaroni Grill\", 'href': 'restaurants/39.html'}, {'name': 'Ruby Tuesday', 'href': 'restaurants/40.html'}, {'name': 'Subway', 'href': 'restaurants/41.html'}, {'name': 'Taco Bell', 'href': 'restaurants/42.html'}, {'name': 'Taco Bueno', 'href': 'restaurants/43.html'}, {'name': \"Wendy's\", 'href': 'restaurants/44.html'}]\n"
     ]
    }
   ],
   "source": [
    "#WOW THIS TOOK FOREVER LOL \n",
    "#5.02-lesson-webscraping/solution-code/Codealong.ipynb\n",
    "\n",
    "restaurants = []\n",
    "for each in soup.find_all('a'):\n",
    "    rest = {}\n",
    "    rest['name'] = each.text\n",
    "    rest['href'] = each.attrs['href']\n",
    "\n",
    "    restaurants.append(rest)\n",
    "print(restaurants)\n",
    "\n",
    "# df = pd.DataFrame(rests)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using the `href`, scrape each restaurant's page and create a single list of food dictionaries.\n",
    "\n",
    "Your list of foods should look something like this:\n",
    "```python\n",
    "foods = [\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**: Remove extra white space from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pages.git.generalassemb.ly/rldaggie/for-scraping/')\n",
    "\n",
    "# Configure this to the root of the above website, e.g. 'http://www.mywebsite.com'\n",
    "base_url = \"https://pages.git.generalassemb.ly/rldaggie/for-scraping/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for loop to iterate over list of hrefs and then open the page with the restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(base_url + df['href'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/1.html\n"
     ]
    }
   ],
   "source": [
    "print(base_url + df['href'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dic in restaurants:\n",
    "#     for keys,values in dic.items():\n",
    "#         print (values)\n",
    "        \n",
    "# requests.get(base_url + restaurants[dict_item[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(base_url+str(restaurants[4]['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSchema",
     "evalue": "No connection adapters were found for \"['https://pages.git.generalassemb.ly/rldaggie/for-scraping//', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/1.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/2.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/3.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/4.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/5.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/6.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/7.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/8.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/9.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/10.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/11.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/12.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/13.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/14.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/15.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/16.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/17.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/18.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/19.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/20.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/21.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/22.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/23.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/24.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/25.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/26.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/27.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/28.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/29.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/30.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/31.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/32.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/33.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/34.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/35.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/36.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/37.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/38.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/39.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/40.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/41.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/42.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/43.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/44.html']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-be406cae9cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrestaurants\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Get the appropriate adapter to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# Start time (approximately) of the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget_adapter\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# Nothing matches :-/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No connection adapters were found for {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidSchema\u001b[0m: No connection adapters were found for \"['https://pages.git.generalassemb.ly/rldaggie/for-scraping//', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/1.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/2.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/3.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/4.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/5.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/6.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/7.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/8.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/9.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/10.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/11.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/12.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/13.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/14.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/15.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/16.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/17.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/18.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/19.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/20.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/21.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/22.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/23.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/24.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/25.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/26.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/27.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/28.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/29.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/30.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/31.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/32.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/33.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/34.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/35.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/36.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/37.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/38.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/39.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/40.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/41.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/42.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/43.html', 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/44.html']\""
     ]
    }
   ],
   "source": [
    "requests.get([base_url+p['href'] for p in restaurants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a pandas DataFrame from your list of foods\n",
    "\n",
    "**Note**: Your DataFrame should have 5,131 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Export to csv\n",
    "\n",
    "**Note:** Don't export the index column from your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
